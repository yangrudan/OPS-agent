import os
import json
import time
import chromadb  # ç›´æ¥ä½¿ç”¨chromadbåŸç”Ÿåº“
from dotenv import load_dotenv
from mofa.agent_build.base.base_agent import run_agent,MofaAgent
from sentence_transformers import SentenceTransformer  # ç›´æ¥ç”¨sentence-transformersç”Ÿæˆå‘é‡
from chromadb.utils import embedding_functions  # Chromaçš„åµŒå…¥å·¥å…·ç±»
from mofa.utils.files.read import read_yaml

class OPSMemoryAgent:
    def __init__(self, config_path):
        self.yml_config = read_yaml(config_path)["agent"]
        self._load_env()

        # 1. åˆå§‹åŒ–ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆç›´æ¥ç”¨sentence-transformersï¼Œä¸ä¾èµ–mem0ï¼‰
        self.embed_model = self._init_embed_model()

        # 2. åˆå§‹åŒ–Chromaå‘é‡åº“ï¼ˆç›´æ¥ç”¨chromadbåŸç”ŸAPIï¼Œä¸ä¾èµ–mem0ï¼‰
        self.chroma_client, self.collection = self._init_chroma()

        # åˆå§‹åŒ–MOFAä»£ç†
        # self.agent = MofaAgent(agent_name='ops-memory-agent')

    def _load_env(self):
        load_dotenv('ops.env')
        self.user_id = os.getenv('MEMORY_ID', 'ops-admin')  # åŒºåˆ†ç”¨æˆ·
        self.memory_limit = int(os.getenv('MEMORY_LIMIT', 100))  # è®°å¿†ä¸Šé™
        self.chroma_path = self.yml_config["vector_store"]["config"]["path"]  # Chromaå­˜å‚¨è·¯å¾„
        self.collection_name = self.yml_config["vector_store"]["config"]["collection_name"]  # é›†åˆå

    def _init_embed_model(self):
        """åˆå§‹åŒ–ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆBAAI/bge-small-zh-v1.5ï¼‰"""
        model_name = self.yml_config["embedder"]["config"]["model"]
        # ç›´æ¥åŠ è½½æœ¬åœ°æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½åˆ°~/.cache/huggingfaceï¼‰
        return SentenceTransformer(model_name, device="cpu")  # å¼ºåˆ¶CPUè¿è¡Œ

    def _init_chroma(self):
        """ç›´æ¥åˆå§‹åŒ–Chromaå®¢æˆ·ç«¯å’Œé›†åˆï¼ˆç»•å¼€mem0ï¼‰"""
        # 1. åˆ›å»ºChromaæŒä¹…åŒ–å®¢æˆ·ç«¯ï¼ˆæ•°æ®å­˜åœ¨æœ¬åœ°è·¯å¾„ï¼‰
        client = chromadb.PersistentClient(path=self.chroma_path)
        
        # 2. è·å–æˆ–åˆ›å»ºé›†åˆï¼ˆè‹¥ä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºï¼‰
        # æ³¨æ„ï¼šä¸æŒ‡å®šembedding_functionï¼Œåç»­æ‰‹åŠ¨ä¼ å…¥å‘é‡
        collection = client.get_or_create_collection(
            name=self.collection_name,
            metadata={"description": "OPSé¡¹ç›®è€å¹´äººè®°å¿†å­˜å‚¨é›†åˆ"}
        )
        print(f"âœ… Chromaå‘é‡åº“åˆå§‹åŒ–æˆåŠŸï¼Œé›†åˆåï¼š{self.collection_name}ï¼Œè·¯å¾„ï¼š{self.chroma_path}")
        return client, collection

    def add_memory(self, content, metadata=None):
        """æ·»åŠ è®°å¿†ï¼šæ‰‹åŠ¨ç”Ÿæˆå‘é‡ï¼Œç›´æ¥å­˜å…¥Chroma"""
        metadata = metadata or {}
        # ç»™è®°å¿†æ·»åŠ ç”¨æˆ·IDï¼ˆç¡®ä¿æœç´¢æ—¶åªè¿”å›å½“å‰ç”¨æˆ·çš„è®°å¿†ï¼‰
        metadata["user_id"] = self.user_id
        
        # 1. æ‰‹åŠ¨ç”Ÿæˆä¸­æ–‡å†…å®¹çš„åµŒå…¥å‘é‡ï¼ˆç”¨sentence-transformersï¼‰
        embedding = self.embed_model.encode(content, convert_to_tensor=False)
        
        # 2. ç”Ÿæˆå”¯ä¸€IDï¼ˆé¿å…é‡å¤å­˜å‚¨ï¼Œæ ¼å¼ï¼šç”¨æˆ·ID_æ—¶é—´æˆ³ï¼‰
        memory_id = f"{self.user_id}_{int(time.time() * 1000)}"  # æ—¶é—´æˆ³ç²¾ç¡®åˆ°æ¯«ç§’
        
        # 3. å­˜å…¥Chromaï¼šidã€å‘é‡ã€æ–‡æœ¬ã€å…ƒæ•°æ®
        self.collection.add(
            ids=[memory_id],
            embeddings=[embedding],
            documents=[content],
            metadatas=[metadata]
        )
        print(f"âœ… å·²æ·»åŠ è®°å¿†ï¼ˆIDï¼š{memory_id[:10]}...ï¼‰ï¼š{content[:30]}...")

        # ä¿®å‰ªæ—§è®°å¿†
        self._prune_old_memory()

    def search_memory(self, query, limit=None,  similarity_threshold=0.6, person_filter=None):
        """æœç´¢è®°å¿†ï¼šæ‰‹åŠ¨ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼Œåœ¨Chromaä¸­åŒ¹é…"""
        limit = limit or self.memory_limit
        
        # 1. ç”ŸæˆæŸ¥è¯¢è¯çš„åµŒå…¥å‘é‡
        query_embedding = self.embed_model.encode(query, convert_to_tensor=False)

        # æ„å»ºè¿‡æ»¤æ¡ä»¶ï¼šç”¨æˆ·ID + äººç‰©æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
        filter_cond = {"user_id": self.user_id}
        if person_filter:
            # æ¨¡ç³ŠåŒ¹é…äººç‰©æ ‡ç­¾ï¼ˆå¦‚person_filter="å¥¶å¥¶"ï¼ŒåŒ¹é…å«â€œå¥¶å¥¶â€çš„personï¼‰
            filter_cond["person"] = {"$contains": person_filter}

        # è·å–ChromaåŸå§‹ç»“æœ
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=limit,
            where={"user_id": self.user_id},
            include=["documents", "metadatas", "distances"]
        )
        #æ‰“å°åŸå§‹ç»“æœï¼ˆé‡ç‚¹çœ‹documentså’Œmetadatasæ˜¯å¦æœ‰æ•°æ®ï¼‰
        print(f"ğŸ“ è°ƒè¯•æ—¥å¿—ï¼šChromaè¿”å›åŸå§‹ç»“æœï¼š")
        print(f"  - æ–‡æ¡£æ•°é‡ï¼š{len(results['documents'][0])}")
        print(f"  - æ–‡æ¡£å†…å®¹ï¼š{results['documents'][0]}")
        print(f"  - å…ƒæ•°æ®ï¼š{results['metadatas'][0]}")
        print(f"  - è·ç¦»ï¼š{results['distances'][0]}")
        

        # 3. è®¡ç®—ç›¸ä¼¼åº¦å¹¶è¿‡æ»¤ï¼ˆChromaè¿”å›çš„æ˜¯cosineè·ç¦»ï¼Œç›¸ä¼¼åº¦=1-è·ç¦»ï¼‰
        formatted_results = []
        documents = results.get("documents", [[]])[0]
        metadatas = results.get("metadatas", [[]])[0]
        distances = results.get("distances", [[]])[0]
        
        # éå†ç»“æœï¼Œä¼˜åŒ–ç›¸ä¼¼åº¦è®¡ç®—
        for doc, meta, dist in zip(documents, metadatas, distances):
            if not doc:
                continue
            
            # ä¼˜åŒ–1ï¼šç›¸ä¼¼åº¦è®¡ç®—ï¼ˆæ·»åŠ è¾¹ç•Œä¿æŠ¤ï¼Œç¡®ä¿åœ¨0-1åŒºé—´ï¼‰
            similarity = 1 - (dist / 2)
            similarity = max(similarity, 0.0)  # é¿å…ç›¸ä¼¼åº¦ä¸ºè´Ÿ
            similarity = min(similarity, 1.0)  # é¿å…ç›¸ä¼¼åº¦è¶…è¿‡1
            
            # ä¼˜åŒ–2ï¼šæ‰“å°è®¡ç®—æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•
            # print(f"ğŸ“Š ç›¸ä¼¼åº¦è®¡ç®—ï¼šå…³é”®è¯'{query}' vs è®°å¿†'{doc[:20]}...'")
            # print(f"  - cosineè·ç¦»ï¼š{round(dist, 3)}")
            # print(f"  - è®¡ç®—ç›¸ä¼¼åº¦ï¼š{round(similarity, 3)}ï¼ˆé˜ˆå€¼ï¼š{similarity_threshold}ï¼‰")
            
            # é˜ˆå€¼è¿‡æ»¤ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„ç›¸ä¼¼åº¦ï¼‰
            if similarity >= similarity_threshold:
                # æå–å…ƒæ•°æ®ï¼ˆå…¼å®¹å­—æ®µç¼ºå¤±åœºæ™¯ï¼‰
                mem_type = meta.get("type", "æœªåˆ†ç±»")
                formatted_results.append({
                    "content": doc,
                    "metadata": {"type": mem_type, **meta},
                    "similarity": round(similarity, 3)
                })
        
        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        formatted_results.sort(key=lambda x: x["similarity"], reverse=True)
        return formatted_results

    def _prune_old_memory(self):
        """ä¿®å‰ªæ—§è®°å¿†ï¼šè¶…å‡ºä¸Šé™æ—¶åˆ é™¤æœ€æ—©çš„è®°å¿†ï¼ˆæŒ‰IDä¸­çš„æ—¶é—´æˆ³æ’åºï¼‰"""
        # 1. æŸ¥è¯¢å½“å‰ç”¨æˆ·çš„æ‰€æœ‰è®°å¿†ï¼ˆæŒ‰IDå‡åºï¼ŒIDåŒ…å«æ—¶é—´æˆ³ï¼Œæœ€æ—©çš„åœ¨å‰ï¼‰
        all_memories = self.collection.get(
            where={"user_id": self.user_id},
            include=["metadatas"]  # åªéœ€è·å–IDå’Œå…ƒæ•°æ®ï¼Œæ— éœ€å‘é‡å’Œæ–‡æœ¬
        )
        memory_ids = all_memories["ids"]
        if len(memory_ids) <= self.memory_limit:
            return  # æœªè¶…å‡ºä¸Šé™
        
        # 2. è®¡ç®—éœ€è¦åˆ é™¤çš„æ—§è®°å¿†æ•°é‡å’ŒID
        num_to_delete = len(memory_ids) - self.memory_limit
        old_ids = memory_ids[:num_to_delete]  # å–æœ€æ—©çš„Næ¡ID
        
        # 3. åˆ é™¤æ—§è®°å¿†
        self.collection.delete(ids=old_ids)
        print(f"ğŸ—‘ï¸  å·²ä¿®å‰ª{num_to_delete}æ¡æ—§è®°å¿†ï¼Œå½“å‰å‰©ä½™{len(memory_ids)-num_to_delete}æ¡")

    def run(self):
        """è¿è¡ŒMOFAä»£ç†ï¼Œæ¥æ”¶å¤–éƒ¨æŒ‡ä»¤"""
        # @self.agent.run_agent
        def process(agent: MofaAgent):
            print("\nğŸš€ OPSè®°å¿†ä»£ç†å·²å¯åŠ¨ï¼Œç­‰å¾…æ¥æ”¶æ¶ˆæ¯...")
            while True:
                message = agent.receive_parameter("ops_message")
                if not message:
                    continue
                
                # è§£æJSONæ¶ˆæ¯
                try:
                    msg_data = json.loads(message)
                except json.JSONDecodeError:
                    print("âŒ æ¶ˆæ¯æ ¼å¼é”™è¯¯ï¼éœ€ä¸ºJSONå­—ç¬¦ä¸²ï¼ˆç¤ºä¾‹ï¼š{\"type\":\"store\",\"content\":\"xxx\"}ï¼‰")
                    continue
                
                # å¤„ç†å­˜å‚¨æŒ‡ä»¤
                if msg_data.get("type") == "store":
                    content = msg_data.get("content")
                    if not content:
                        print("âŒ å­˜å‚¨å¤±è´¥ï¼šè®°å¿†å†…å®¹ä¸èƒ½ä¸ºç©ºï¼")
                        continue
                    self.add_memory(
                        content=content,
                        metadata=msg_data.get("metadata", {})
                    )
                    # è¿”å›å­˜å‚¨çŠ¶æ€
                    agent.send_output(
                        "memory_status",
                        agent_result=json.dumps({"status": "success", "msg": "è®°å¿†å­˜å‚¨æˆåŠŸ"}),
                        is_end_status=True
                    )
                
                # å¤„ç†æœç´¢æŒ‡ä»¤
                elif msg_data.get("type") == "search":
                    query = msg_data.get("query")
                    if not query:
                        print("âŒ æœç´¢å¤±è´¥ï¼šæŸ¥è¯¢è¯ä¸èƒ½ä¸ºç©ºï¼")
                        continue
                    results = self.search_memory(query=query)
                    # è¿”å›æœç´¢ç»“æœ
                    agent.send_output(
                        "search_results",
                        agent_result=json.dumps({
                            "status": "success",
                            "count": len(results),
                            "results": results
                        }),
                        is_end_status=True
                    )

if __name__ == "__main__":
    # éªŒè¯é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = os.path.join(os.path.dirname(__file__), "configs", "ops_memory.yml")
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼è·¯å¾„ï¼š{config_path}")
        print("ğŸ’¡ è¯·æ‰§è¡Œ 'ls configs/' ç¡®è®¤æ˜¯å¦å­˜åœ¨ops_memory.yml")
    else:
        ops_agent = OPSMemoryAgent(config_path)
        ops_agent.run()
